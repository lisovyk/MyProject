
done: 
пробіли в colnames <- видає warning
library(tree) for decision trees   - rpart + fancyRpartPlot

to do:
test and train of confusion matrix //todo: add overall accuracy


caret - variables important
add confusion matrix for RF train/test; decision tree

вибір класифікатор (рфорест(mtry+ntree), десіжн трі*)

? static table on tab 3
getting and cleaning data

4 tab - classification

lib caret cross-validation train()
Within cluster sum of squares by total руками порахувати


questions:

lm() quadratic coefficients
how to save values after changing the insides (e.g 2 tab input boxes)

bootstrapLib() for shinyBS

Monte Carlo Simulation in Bootstrap resampling method


normalization if there is only 1 repeated value in column?
if(any(sapply(rv$userTable, is.factor))) {
	for(i in 1:length(colnames(rv$userTable))) {
		if(length(levels(as.factor(rv$userTable[,i]))) == 1) {
		 ...
		}
	}
}





selfedu: 
learn S3 / S4 classes
https://cran.r-project.org/web/packages/EMCluster/EMCluster.pdf

Generative is better in smaller sets, 
but in classification using discriminative is generally better.

• Logistic regression is very popular for classification,
especially when K = 2.
• LDA is useful when n is small, or the classes are well
separated, and Gaussian assumptions are reasonable. Also
when K > 2.
• Naive Bayes is useful when p is very large.
